{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e9f4107-83a1-4cf6-8340-9f9454b57eae",
   "metadata": {},
   "source": [
    "# Distributed Data Analysis with Dask  \n",
    "*__[Dask](https://www.dask.org/)__ with the __MovieLens__ dataset*  \n",
    "\n",
    "**Part 1: Getting Started, Load the MovieLens dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21bef00-086e-44fd-b516-01016a08432d",
   "metadata": {},
   "source": [
    "### <font color='green'>__Support for Google Colab__  </font>  \n",
    "    \n",
    "open this notebook in Colab using the following button:  \n",
    "  \n",
    "<a href=\"https://colab.research.google.com/github/shauryashaurya/learn-data-munging/blob/main/02-Pandas/02.01-Data-Wrangling-with-MovieLens-and-Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>  \n",
    "\n",
    "**Note**: The Dask Dashboard is not available on Google Colab unless you register with tunnelling systems like Saturn Cloud or NGrok - these are both good approaches - for folks running this on colab I have not built support for bit for the workshop. Your contributions / PRs would be very welcome.\n",
    "  \n",
    "<font color='green'>uncomment and execute the cell below to setup and run this notebook on Google Colab.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40fdc1e-8800-47e9-bd9a-cf007406461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SETUP FOR COLAB: select all the lines below and uncomment (CTRL+/ on windows)\n",
    "\n",
    "# # grab dask - in most cases it should already be available in colab\n",
    "# ! python -m pip install --quiet --upgrade --no-cache-dir \"dask[complete]\"\n",
    "# # Let's download and unzip the MovieLens 25M Dataset as well.\n",
    "# ! mkdir ./../data\n",
    "# ! wget -q https://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
    "# ! unzip ./ml-25m.zip -d ./../data/\n",
    "\n",
    "# ! echo \"DONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618beb44-e43c-413d-bbaf-6aee638a79d3",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Select, filter, join, groupby, pivot, and windows.  \n",
    "\n",
    "Instead of toy examples and '10 minutes to xx' we load an actual dataset and ask meaningful questions about it.\n",
    "  \n",
    "We'll use the [MovieLens](https://grouplens.org/datasets/movielens/) dataset for these exercises.  \n",
    "This dataset is non trivial and should expand to about __1GB__ on you local disk.  \n",
    "\n",
    "Download and unzip [MovieLens 25M Dataset](https://grouplens.org/datasets/movielens/25m/) for this analysis.\n",
    "\n",
    "Either ensure the data is in ```\"./data/ml-25m\"``` folder or update the path to the data below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1999f3bc-1a3d-4a4e-a4c2-5634a9cfd0ed",
   "metadata": {},
   "source": [
    "**Citation**:  \n",
    "*F. Maxwell Harper and Joseph A. Konstan.* 2015.  \n",
    "The MovieLens Datasets: History and Context.  \n",
    "ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:1–19:19. <https://doi.org/10.1145/2827872>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e800f817-bb56-4a7e-bbff-94320a85c234",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "The idea is to tackle simple Dask use-cases first and move on to more complex ones.  \n",
    "\n",
    "Starting with simply loading the data into a dask distributed dataframe, we then perform a data evaluation, some cleanup and finally analysis. We first ask questions based on individual data files, then move on to combining data from multiple files.\n",
    "\n",
    "We are going to try and avoid the more mathematically involved parts of exploratory data analysis - for e.g. statistical analysis on various features etc. - the core focus in the ability to grok pyspark functions and have fun while doing it.  \n",
    "\n",
    "By the end you'd not only have an idea of Dask, but also how we ask questions and analyze a chunk of data.  \n",
    "\n",
    "_You may also end up with a watch-list to binge on your next weekend._ :)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b518bef-b08d-40ff-b63b-7395f06de060",
   "metadata": {},
   "source": [
    "# Setup Dask, Pandas and Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d77b71-0373-43bd-8011-1c05b5b18e60",
   "metadata": {},
   "source": [
    "## Setup the Dask Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938fa94c-777e-41ed-8f50-d9d6d37f2a2c",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "A local install is as simple as ```pip install \"dask[complete]\"```  \n",
    "  \n",
    "Unlike Spark, Dask is incredibly easy to setup - checkout [Dask Installation Docs](https://docs.dask.org/en/stable/install.html)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe72515-0873-4f40-b574-024ef66bc31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version:  1.26.0\n",
      "pandas version:  2.1.1\n"
     ]
    }
   ],
   "source": [
    "# Step 1: numpy and pandas\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"numpy version: \", np.__version__)\n",
    "print(\"pandas version: \", pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19defc56-381c-45fb-b93c-a3ddc5444e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask version:  2023.9.2\n"
     ]
    }
   ],
   "source": [
    "# Step 2: import dask and related\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "print(\"dask version: \", dask.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900c43d8-421d-4113-a83c-685e5716fa1b",
   "metadata": {},
   "source": [
    "![Dask](https://docs.dask.org/en/stable/_images/dask-overview.svg)\n",
    "\n",
    "<font size = '2px' color='green'>Image from docs.dask.org</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4028755-bd5d-40e0-a1bd-1de6f835cb19",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3: Create a Dask Cluster and a Client\n",
    "try:\n",
    "    cluster = LocalCluster()\n",
    "    # alternative, when you want to specify the dashboard address/port\n",
    "    # cluster = LocalCluster(dashboard_address = 'localhost:8786')\n",
    "    if (cluster.shutdown_on_close == False):\n",
    "        cluster.shutdown_on_close = True\n",
    "except Exception:\n",
    "    pass\n",
    "#\n",
    "try:\n",
    "    client = Client(cluster)\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ebfabd9-4706-4ba3-a0e9-5cd3f795444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see cluster information\n",
    "# cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59053c50-23ba-49b7-b64c-23ea049d86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see client information\n",
    "# client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb164ece-2d5e-4451-b455-24fe2add5bee",
   "metadata": {},
   "source": [
    "# Locate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a045b14-f578-47ad-9972-a3f5aaba0911",
   "metadata": {},
   "outputs": [],
   "source": [
    "datalocation = \"../data/ml-25m/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0428c276-5ef7-4bde-addf-3bb79337783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify file names\n",
    "file_path_movies = datalocation + \"movies.csv\"\n",
    "file_path_links = datalocation + \"links.csv\"\n",
    "file_path_ratings = datalocation + \"ratings.csv\"\n",
    "file_path_tags = datalocation + \"tags.csv\"\n",
    "file_path_genome_tags = datalocation + \"genome-tags.csv\"\n",
    "file_path_genome_scores = datalocation + \"genome-scores.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378858af-d886-4fd1-a414-6fc489cf898e",
   "metadata": {},
   "source": [
    "## Schema Spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96574358-90c0-4eed-8f4e-1dd5692bd60c",
   "metadata": {},
   "source": [
    "# Load the dataset(s)\n",
    "\n",
    "From the ```README.txt``` file in the small MovieLens dataset:\n",
    "The dataset files are written as [**comma-separated values**](http://en.wikipedia.org/wiki/Comma-separated_values) files with a **single header row**. Columns that contain commas (`,`) are **escaped using double-quotes (`\"`)**. These files are encoded as **UTF-8**. If accented characters in movie titles or tag values (e.g. Misérables, Les (1995)) display incorrectly, make sure that any program reading the data, such as a text editor, terminal, or script, is configured for UTF-8.\n",
    "\n",
    "So, we specify:\n",
    "* Separator - ```,```\n",
    "* Escape Character - ```\"```\n",
    "* Encoding - ```UTF-8```\n",
    "\n",
    "Often this is called the **dialect** of the CSV file.\n",
    "These dialects vary often, so need our attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51505e23-1133-4302-beaf-1690963ec807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask dataframes parallelize pandas dataframes\n",
    "# so many of the idioms are similar\n",
    "csv_separator = \",\"\n",
    "csv_escapechar = '\"'\n",
    "csv_quotechar = csv_escapechar\n",
    "csv_encoding = \"utf-8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503f86f0-c81b-4f2c-80ab-090afbe049d2",
   "metadata": {},
   "source": [
    "## Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2583f6a3-72c2-4414-9c12-b56ac69fb00a",
   "metadata": {},
   "source": [
    "Let's specify the [-  ```dtypes```  ](https://pandas.pydata.org/docs/user_guide/basics.html#dtypes) of each of the columns in the movies file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9a1e502-96a1-4ae1-91e9-cba5e695e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema, inferred from the README.txt file\n",
    "movies_schema = {\"movieId\": \"Int32\", \"title\": \"string\", \"genres\": \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39569d7e-8c3c-44f2-a40b-776adc33d13d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Two of the columns are [strings of text](https://pandas.pydata.org/docs/user_guide/text.html#working-with-text-data). Pandas may treat those as ```object```, but we wanted to use the [```pandas.StringDType```](https://pandas.pydata.org/docs/reference/api/pandas.StringDtype.html#pandas-stringdtype) here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c90ad76-3592-4ed7-8c9f-fc67b94648d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are using dd - dask.dataframe\n",
    "movies = dd.read_csv(\n",
    "    file_path_movies,\n",
    "    dtype=movies_schema,\n",
    "    sep=csv_separator,\n",
    "    quotechar=csv_quotechar,\n",
    "    encoding=csv_encoding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3440485a-172d-4fbf-8970-d88c5f1c7cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b032d0-cd24-4aa7-8d98-422ba8d4900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first 15 lines\n",
    "movies.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c4106b-64cb-4512-94f7-94bc37bf1abb",
   "metadata": {},
   "source": [
    "Look at Row #10 - \"American President, The (1995)\" - so pandas seems to have correctly interpreted the quotation marks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f26c28-7c33-4615-9258-b066884735fa",
   "metadata": {},
   "source": [
    "For now we'll keep things simple and let pandas give us an index.  \n",
    "In some cases it would be interesting to use the ```movieId``` column [as the index](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas.read_csv:~:text=index_colHashable%2C%20Sequence%20of%20Hashable%20or%20False%2C%20optional).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d5f6a-1be8-496b-9d75-ebd120a3475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data types of each column\n",
    "movies.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21309cbb-2489-4b4d-96cc-6532de8cc6bb",
   "metadata": {},
   "source": [
    "Just for practice, let's load the other datasets too..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ca7df0-19e3-4535-99ec-efe5dd1c6dfd",
   "metadata": {},
   "source": [
    "## Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e6aa7b-4f71-4e33-95fb-a74b9014368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema, inferred from the README.txt file\n",
    "# load imdbId,tmdbId as strings because the are a part of a URL.\n",
    "#   IMDB: http://www.imdb.com/title/imdbId/\n",
    "#   TMDB: https://www.themoviedb.org/movie/tmdbId\n",
    "links_schema = {\"movieId\": \"Int32\", \"imdbId\": \"string\", \"tmdbId\": \"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0390f3-e09e-4a66-a335-23e71a15ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv(\n",
    "    file_path_links,\n",
    "    dtype=links_schema,\n",
    "    sep=csv_separator,\n",
    "    quotechar=csv_quotechar,\n",
    "    encoding=csv_encoding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa2447-2217-46e3-968f-6da807d7fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "links.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a2d76-69ab-4f49-a6d2-262c84e14257",
   "metadata": {},
   "outputs": [],
   "source": [
    "links.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e7b872-1db9-49c9-9288-d327cae2fdf1",
   "metadata": {},
   "source": [
    "## Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342bbe4a-c904-4313-8b31-252dc87cda76",
   "metadata": {},
   "source": [
    "Reading through the ```README``` file:  \n",
    "Ratings are made on a 5-star scale, with half-star increments (0.5 stars - 5.0 stars).  \n",
    "Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee402a-94df-4afb-b691-2c1397ea3f36",
   "metadata": {},
   "source": [
    "Ooh! Ooh! We got our first [DateTime](https://pandas.pydata.org/docs/reference/api/pandas.DatetimeTZDtype.html#pandas.DatetimeTZDtype)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672561a7-1b7f-4168-aaec-85245faec9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema, inferred from the README.txt file\n",
    "# read timestamps as integers then convert to dates later.\n",
    "\n",
    "ratings_schema = {\n",
    "    \"userId\": \"Int32\",\n",
    "    \"movieId\": \"Int32\",\n",
    "    \"rating\": \"Float32\",\n",
    "    \"timestamp\": \"Int64\",\n",
    "}\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d102b11-3aca-43ef-977a-21c67ca7f610",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\n",
    "    file_path_ratings,\n",
    "    dtype=ratings_schema,\n",
    "    sep=csv_separator,\n",
    "    quotechar=csv_quotechar,\n",
    "    encoding=csv_encoding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f36be99-fb8b-48d4-897a-d1076092022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fda8643-8179-4e79-9c56-663a66830e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's add a datetime column that we derive from the raw timestamp\n",
    "ratings[\"datetime\"] = pd.to_datetime(ratings[\"timestamp\"], unit=\"s\", utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1a2a42-ed8b-4a45-a90c-a8e97d5b7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b57798-6cab-47b1-8cad-da71d7735d41",
   "metadata": {},
   "source": [
    "#### ```pandas.Series.dt.date```  \n",
    "Let's [extract the dates](https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.date.html#pandas-series-dt-date) into a new column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039e6b08-604e-4095-aad4-c227a27a5362",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "...just in case you are wondering what's that [```dt``` part](https://github.com/pandas-dev/pandas/blob/9e1096e8373bc99675fd1b3490cfb7cf26041395/pandas/core/series.py#L5777C1-L5777C2), and want to dive into the code where it's defined as a [CachedAccessor](https://github.com/pandas-dev/pandas/blob/9e1096e8373bc99675fd1b3490cfb7cf26041395/pandas/core/accessor.py#L196) for ```datetimelike``` values in ```pandas/core/accessor.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa55cc44-f2f2-435f-ab47-2553bbbdcc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[\"date\"] = ratings[\"datetime\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b634931a-1b8f-48d2-a399-b932dcba0cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8a743c-d528-4e02-8b3f-4658951b7dc1",
   "metadata": {},
   "source": [
    "Niiice!  \n",
    "Wait, let's check the data types once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed38a86b-2820-43e3-9cd5-e1752e481f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17bfb7b-4963-4520-bb35-47b859392b42",
   "metadata": {},
   "source": [
    "We'd prefer if date was a datetime type as well.  \n",
    "Let's prepare the date column again, wrapping it in ```pd.to_datetime()```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2d2175-123f-4866-83e9-678ea4655e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[\"date\"] = pd.to_datetime(ratings[\"datetime\"].dt.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeec631-6ec1-45a4-a1a9-8f25d691c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data types again\n",
    "ratings.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e558931-f805-49c1-acff-3bc99c80418d",
   "metadata": {},
   "source": [
    "Ah! much better.  \n",
    "Why you say?  \n",
    "We could easily extract and manipulate dates this way.  \n",
    "for e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9207f2d-cf0d-41b9-bc43-8eefce4ab1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the day, month and year of each rating\n",
    "ratings[\"day\"] = ratings[\"date\"].dt.day\n",
    "ratings[\"month\"] = ratings[\"date\"].dt.month\n",
    "ratings[\"year\"] = ratings[\"date\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f4fab2-5691-4bf2-89cd-aef1c90dcd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c962401-b2e3-4678-911d-8a9cd9ac9064",
   "metadata": {},
   "source": [
    "very clean!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa35971-7b52-44ef-86d8-d413e9924420",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae72f8b9-6d60-47f6-a9c3-33a21c985bc1",
   "metadata": {},
   "source": [
    "Let's do this for the Tags data set too - just for practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f67371-838c-48fd-967d-c2d9c9c210f8",
   "metadata": {},
   "source": [
    "\n",
    "## Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9e1cbe-bd07-4926-b770-b7e476ed09e3",
   "metadata": {},
   "source": [
    "From ```README```:  \n",
    "Tags are user-generated metadata about movies. Each tag is typically a single word or short phrase. The meaning, value, and purpose of a particular tag is determined by each user.  \n",
    "  \n",
    "Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e98718-59dd-4682-87bd-38019d1a792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema, inferred from the README.txt file\n",
    "# read timestamps as integers then convert to dates later.\n",
    "# userId,movieId,tag,timestamp\n",
    "tags_schema = {\n",
    "    \"userId\": \"Int32\",\n",
    "    \"movieId\": \"Int32\",\n",
    "    \"tag\": \"string\",\n",
    "    \"timestamp\": \"Int64\",\n",
    "}\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823b2316-bdc9-4081-b903-c67b2cac472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_csv(\n",
    "    file_path_tags,\n",
    "    dtype=tags_schema,\n",
    "    sep=csv_separator,\n",
    "    quotechar=csv_quotechar,\n",
    "    encoding=csv_encoding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5bb70a-e903-4962-b4e9-abc7521937ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb95a477-114e-4372-9119-1ffc0c18de23",
   "metadata": {},
   "source": [
    "just like before let's add a more readable ```datetime``` column here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bbfb1e-95b3-4448-a639-5a06f625b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags[\"datetime\"] = pd.to_datetime(tags[\"timestamp\"], unit=\"s\", utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c21c7a-bf91-417f-bcb4-6f86e86930ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de8efdd-9f30-46b5-84b5-195ab949c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract date into a new column\n",
    "tags[\"date\"] = pd.to_datetime(tags[\"datetime\"].dt.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e7d50-0b07-4062-929c-e292aa57399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1723c691-f631-4550-b4f5-cb2f787b56ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eb6c9f-d156-48fa-801c-754e0c899aac",
   "metadata": {},
   "source": [
    "umm... go nuts.  \n",
    "Extract the day, month and year from date, because why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f6aeb1-3a1b-46da-be87-292161d9d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags[\"day\"] = tags[\"date\"].dt.day\n",
    "tags[\"month\"] = tags[\"date\"].dt.month\n",
    "tags[\"year\"] = tags[\"date\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1618bd04-750f-499a-a635-8415854b17c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13fbf25-2912-42ce-bb00-3862404de8d0",
   "metadata": {},
   "source": [
    "# Wrap Up the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc23986a-d022-4dac-a0b6-148c69941bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap up like this\n",
    "client.retire_workers()\n",
    "# QQ - do we really need cluster.close() here?\n",
    "# cluster.close()\n",
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e87a98-9330-49cd-8bbb-78bf7f38ac1d",
   "metadata": {},
   "source": [
    "# Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c32a1f8-01d0-4685-91a4-48abb08dc38a",
   "metadata": {},
   "source": [
    "1. For CSV data pay attention to the dialect\n",
    "2. EscapeChar vs QuoteChar in Pandas\n",
    "3. Opinion: Safe approach for timestamps - import as Integers/Numeric and convert using ```pd.to_datetime```\n",
    "4. ```pandas.Series.dt.date```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd9648-5a13-446f-a775-76616ace03c1",
   "metadata": {},
   "source": [
    "# Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30f9979-d5c1-4fa6-875d-76e2c017ec76",
   "metadata": {},
   "source": [
    "* Let's play with the MovieLens dataset some more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
