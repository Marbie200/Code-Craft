{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1465e88d-990a-4ddd-aaae-676c35428150",
   "metadata": {},
   "source": [
    "# Analysis with Polars  \n",
    "*__[Polars](https://www.pola.rs/)__ with the __MovieLens__ dataset*  \n",
    "\n",
    "**Part 1: Getting Started, Load the MovieLens dataset and some analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ce9ba8-4644-443d-b350-1292cb318deb",
   "metadata": {},
   "source": [
    "### <font color='green'>__Support for Google Colab__  </font>  \n",
    "    \n",
    "open this notebook in Colab using the following button:  \n",
    "  \n",
    "<a href=\"https://colab.research.google.com/github/shauryashaurya/learn-data-munging/blob/main/02-Pandas/02.01-Data-Wrangling-with-MovieLens-and-Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>  \n",
    "  \n",
    "<font color='green'>uncomment and execute the cell below to setup and run this notebook on Google Colab.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02e862f-a6cb-4edc-9607-65c546093288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SETUP FOR COLAB: select all the lines below and uncomment (CTRL+/ on windows)\n",
    "# !pip install polars\n",
    "# # Let's download and unzip the Small MovieLens Dataset\n",
    "# ! mkdir ./../data\n",
    "# ! wget -q https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "# ! unzip ./ml-latest-small.zip -d ./../data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aec6cd-a3d9-495c-a22d-2fc043329ff5",
   "metadata": {},
   "source": [
    "### Get the _Small_ MovieLens Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf19837-1947-4d0f-9d5d-8928f4abbb58",
   "metadata": {},
   "source": [
    "We'll use the [small MovieLens dataset](https://grouplens.org/datasets/movielens/#:~:text=Small%3A%20100%2C000%20ratings%20and%203%2C600%20tag%20applications) here.\n",
    "\n",
    "Download it and unzip to the data folder under the name `ml-latest-small`.\n",
    "\n",
    "This dataset expands to about 3.2 MB on your local disk. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b1ea04-3a54-485a-b90b-004199995c5d",
   "metadata": {},
   "source": [
    "# Locate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa24e9d9-cb1d-4919-b158-5cd6ee99cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datalocation = \"./../data/ml-latest-small/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe35748-ddf3-4361-bf3a-f802f6d1b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify file names\n",
    "file_path_movies = datalocation + \"movies.csv\"\n",
    "file_path_links = datalocation + \"links.csv\"\n",
    "file_path_ratings = datalocation + \"ratings.csv\"\n",
    "file_path_tags = datalocation + \"tags.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7dd911-be3a-4c64-991b-5af4f3a0a232",
   "metadata": {},
   "source": [
    "# Setup Polars, Pandas and Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f7898-9e8e-41dc-a096-3d62af8a2152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "print(\"numpy version: \", np.__version__)\n",
    "print(\"pandas version: \", pd.__version__)\n",
    "print(\"polars version: \",pl.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd83acca-0b4c-438f-9c6e-381147946a8f",
   "metadata": {},
   "source": [
    "# A note on Apache Arrow and the Columnar Memory Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acca991-194e-4fe8-a90b-26d6c45c4072",
   "metadata": {},
   "source": [
    "**Apache Arrow? What?**\n",
    "[Apache Arrow](https://arrow.apache.org/) is an open-source, cross-language development platform for in-memory data. It specifies a standardized, language-agnostic Columnar Memory Format for flat and hierarchical data, organized for efficient analytic operations on modern hardware.  \n",
    "\n",
    "**Aside** - [Wes McKinney's Apache Arrow and the “10 Things I Hate About pandas”](https://wesmckinney.com/blog/apache-arrow-pandas-internals/), read up!  \n",
    "\n",
    " **Importance and Benefits**: Arrow enables data systems to process and transfer data quickly. Its columnar memory format allows systems to avoid serialization costs, improving performance for analytics and data interchange  \n",
    "\n",
    "That word again - **Columnar**.  \n",
    "To refresh:\n",
    "\n",
    "![Columnar Representation](./../images/Column-Wise-Representation.drawio.png)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bc6f16-6570-43ae-adeb-a09b1d60c3a6",
   "metadata": {},
   "source": [
    "## **Arrow Memory Model**:  \r\n",
    "   - **Arrow’s Columnar Memory Layout**: Instead of storing data row-wise, Arrow stores data column-wise, which means data for a single column is stored together in memory  .\r\n",
    "   - **Benefits for Analytics**: Storing data column-wise is beneficial for analytics because operations tend to focus on subsets of columns rather than entire rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df31fef1-c143-4cde-b482-1d5fd280dec8",
   "metadata": {},
   "source": [
    "Here's how Apache Arrow's columnar memory format benefits various operations:\r\n",
    "\r\n",
    "### 1. **Better Cache Locality**\r\n",
    "\r\n",
    "Traditional row-wise storage often leads to unnecessary cache misses when performing operations on specific columns. In a columnar format, since the data is stored continuously in memory, operations on a column benefit from better cache locality. \r\n",
    "\r\n",
    "**Example**: Consider summing the values in a column. \r\n",
    "\r\n",
    "In a row-wise format, you'd have to jump through memory for every row, leading to potential cache misses. In a columnar format, the summation is performed on contiguous blocks of memory.\r\n",
    "\r\n",
    "### 2. **Vectorized Operations using SIMD**\r\n",
    "\r\n",
    "Arrow's columnar format pairs perfectly with [SIMD (Single Instruction, Multiple Data)](https://en.wikipedia.org/wiki/Flynn%27s_taxonomy). SIMD allows a single operation to be performed on multiple data points simultaneously. When data is stored in columns, vectorized operations can efficiently process multiple data points in a single column at once.\r\n",
    "\r\n",
    "**Example**: Consider multiplying every value in a column by 2.\r\n",
    "\r\n",
    "With SIMD and columnar storage, multiple entries from that column can be loaded into large registers and multiplied by 2 simultaneously, speeding up the operation.\r\n",
    "\r\n",
    "### 3. **Efficient Compression and Encoding**\r\n",
    "\r\n",
    "Columnar data can be compressed more effectively than row-wise data. This is because adjacent values in a column often have similar lengths and patterns, making them suitable for compression algorithms.\r\n",
    "\r\n",
    "**Example**: A column containing the dates for every day in a year would have repetitive year and month values. This repetitiveness can be ethe Parquet file, only the 'name' column's data blocks are loaded, making the read operation faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe52dd2-2d22-4f6e-b24c-842979976a70",
   "metadata": {},
   "source": [
    "### 4. **Sparse Data Handling**\n",
    "\n",
    "In datasets with many missing or null values, columnar storage can be more space-efficient.  \n",
    "A whole column of missing values can be represented compactly.  \n",
    "\n",
    "Consider the following example:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1321fab-2710-4eb7-80e1-a7ac96f9dc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Arrow's columnar format, the missing `age` values don't take up any more space than necessary.\n",
    "import pyarrow as pa\n",
    "\n",
    "data = {\n",
    "    'name': [\"Alice\", \"Bob\", \"Charlie\", None, \"Eve\"],\n",
    "    'age': [25, None, 35, None, 40]\n",
    "}\n",
    "\n",
    "table = pa.table(data)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c596d36-f440-4d77-885b-6179659182c1",
   "metadata": {},
   "source": [
    "### 5. **Less I/O**\n",
    "\n",
    "When querying large datasets stored on disk, columnar formats enable more efficient I/O.  \n",
    "If only specific columns are required, only those columns' data blocks need to be loaded, reducing the I/O overhead.   \n",
    "   \n",
    "Let's look at another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31df91a-a84b-49b7-894f-852cb0db9c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when reading the Parquet file, \n",
    "# only the 'name' column's data blocks are loaded, \n",
    "# making the read operation faster.\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Writing table to a Parquet file (columnar storage)\n",
    "pq.write_table(table,'data.parquet')\n",
    "\n",
    "# Reading only the 'name' column - fast as only 'name' column is read.\n",
    "table_subset = pq.read_table('data.parquet', columns=['name'])\n",
    "print(table_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e82ece0-ad45-4deb-9da3-33dfb4551553",
   "metadata": {},
   "source": [
    "# Back to Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8902828f-ed05-4aa1-8366-f2c80c947141",
   "metadata": {},
   "source": [
    "Polars is still nascent.  \n",
    "But growing real fast!  \n",
    "  \n",
    "The syntax varies from both [Pandas](https://pola-rs.github.io/polars/user-guide/migration/pandas/) and [Spark](https://pola-rs.github.io/polars/user-guide/migration/spark/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a94892-54b9-40f7-a2ee-04a37f42aeeb",
   "metadata": {},
   "source": [
    "# Load the dataset(s)\n",
    "\n",
    "From the ```README.txt``` file in the small MovieLens dataset:\n",
    "The dataset files are written as [**comma-separated values**](http://en.wikipedia.org/wiki/Comma-separated_values) files with a **single header row**. Columns that contain commas (`,`) are **escaped using double-quotes (`\"`)**. These files are encoded as **UTF-8**. If accented characters in movie titles or tag values (e.g. Misérables, Les (1995)) display incorrectly, make sure that any program reading the data, such as a text editor, terminal, or script, is configured for UTF-8.\n",
    "\n",
    "So, we specify:\n",
    "* Separator - ```,```\n",
    "* Escape Character - ```\"```\n",
    "* Encoding - ```UTF-8```\n",
    "* Quore Character - ```\"```\n",
    "\n",
    "Often this is called the **dialect** of the CSV file.\n",
    "These dialects vary often, so need our attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e407c3c-adc4-4e3d-b04b-8257001a030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_separator = \",\"\n",
    "csv_escapechar = '\"'\n",
    "# not 'utf-8'\n",
    "csv_encoding = \"utf8\"\n",
    "csv_quotechar = csv_escapechar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e911ef25-10f1-4b39-b900-9622c2944738",
   "metadata": {},
   "source": [
    "## Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9a1b4b-4484-466d-8ac2-a3a8d6053eca",
   "metadata": {},
   "source": [
    "One of the reasons polars is fast is due to it's insistence on strict data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7620c8-b3a4-48ea-839a-993b8c7f55a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema, inferred from the README.txt file\n",
    "# use polars constants\n",
    "movies_schema = {\"movieId\": pl.UInt32, \n",
    "\t\t\t\t \"title\": pl.Utf8, \n",
    "\t\t\t\t \"genres\": pl.Utf8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b335d-3f3b-4972-8fab-4436a5658701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema instead of dtypes\n",
    "# separator instead of sep\n",
    "# quote_char instead of quotechar\n",
    "movies = pl.read_csv(\n",
    "    source=file_path_movies,\n",
    "\thas_header=True,\n",
    "\tschema=movies_schema,\n",
    "    separator=csv_separator,\n",
    "    quote_char=csv_quotechar,\n",
    "    encoding=csv_encoding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6c136f-9ec4-4761-b418-ea5060c61cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc208846-b2d4-4eda-ad3c-a0bdadf6d1f8",
   "metadata": {},
   "source": [
    "### Expressions  \n",
    "Polars has this notion of [Expressions](https://pola-rs.github.io/polars/user-guide/expressions/operators/) that is central to it's approach.  \n",
    "If you've seen method chains in JavaScript - you will feel very comfortable with Expressions.  \n",
    "Each 'expression' is effectively an operation that can be performed in parallel on data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9718bc4-eaf5-48ce-a7e3-d36bd28e9125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one column\n",
    "# series of all the titles\n",
    "movies.select(pl.col('title')).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4e6b93-5ced-4f5f-bc50-36f2d0244ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all columns\n",
    "movies.select(pl.col('*')).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248cba62-da9b-4159-aa44-7e5ce8d2b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all columns - option 2\n",
    "movies.select(pl.all()).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadc706b-5cf5-425e-9180-b09784700e16",
   "metadata": {},
   "source": [
    "\n",
    "## Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7ab5c2-0c21-4992-8e1c-f4475c801152",
   "metadata": {},
   "source": [
    "From ```README```:  \n",
    "Tags are user-generated metadata about movies. Each tag is typically a single word or short phrase. The meaning, value, and purpose of a particular tag is determined by each user.  \n",
    "  \n",
    "Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1037a9-8405-42db-99a9-1aeb79086c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema, inferred from the README.txt file\n",
    "# read timestamps as integers then convert to dates later.\n",
    "# userId,movieId,tag,timestamp\n",
    "tags_schema = {\n",
    "    \"userId\": pl.UInt32,\n",
    "    \"movieId\": pl.UInt32,\n",
    "    \"tag\": pl.Utf8,\n",
    "    \"timestamp\": pl.UInt64,\n",
    "}\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d1d1e0-dc18-44b0-a2eb-bd9a1bebc821",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pl.read_csv(\n",
    "    source=file_path_tags,\n",
    "\thas_header=True,\n",
    "\tschema=tags_schema,\n",
    "    separator=csv_separator,\n",
    "    quote_char=csv_quotechar,\n",
    "    encoding=csv_encoding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c06164d-92fa-43c1-b715-9993ecd32788",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4141efc-fbb5-469d-9f77-1d8ae829a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include all columns but exclude the timestamp\n",
    "tags.select(pl.all().exclude('timestamp')).head(10)\n",
    "# also\n",
    "# tags.select(pl.col('*').exclude('timestamp')).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef92580-eaeb-4858-96ac-3bf45337377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select just 2 columns\n",
    "tags.select(pl.col('movieId','tag')).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0aa707-cb1b-4c06-922b-9d6d42e7b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a date-time column\n",
    "# does with_Columns remind you of Spark?\n",
    "\n",
    "tags = tags.with_columns(\n",
    "    (pl.col(\"timestamp\")*1000).cast(pl.Datetime).dt.with_time_unit(\"ms\").alias(\"datetime\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd63c4ae-3155-4047-8be3-06fb246e252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e69bc1-573b-4c27-83fc-a61eb3ac305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a date column\n",
    "\n",
    "tags = tags.with_columns(\n",
    "    (pl.col(\"datetime\")).cast(pl.Date).alias(\"date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e11188-76f8-4af3-9401-0acefdf71f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c672e9c1-befb-4a92-85ad-38df63a3e076",
   "metadata": {},
   "source": [
    "# Problem Set 1\n",
    "\n",
    "* How many unique movies in Tags? How many in Movies?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf9bf9c-f3dc-4a5e-99f5-a01d78ac3db8",
   "metadata": {},
   "source": [
    "## Solutions to Problem Set 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d71d81-8be1-4c91-ab20-b89651a97e68",
   "metadata": {},
   "source": [
    "### How many unique movies in Tags? How many in Movies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3bbba0-7669-40e5-8093-41904b33a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "# Series of all the titles\n",
    "movies['title'].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9996b936-63ca-42a7-bea2-6e8f2dcad3ee",
   "metadata": {},
   "source": [
    "two ways to [count unique values](https://pola-rs.github.io/polars/user-guide/expressions/functions/#count-unique-values) in Polars: an exact methodology and an approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad201e-6873-43c8-beb2-5357daa0422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_movies_movies = movies.select(\n",
    "    pl.col('title').n_unique().alias('unique'),\n",
    "    pl.approx_n_unique('title').alias('unique_approx')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1eb9f4-dc0d-43db-a55e-03b291dba607",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_movies_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08062da-a0cb-4459-a986-8c3c60d36a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_movies_tags = movies.select(\n",
    "    pl.col('movieId').n_unique().alias('unique'),\n",
    "    pl.approx_n_unique('movieId').alias('unique_approx')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd905a7e-3381-4966-8a8e-a68356523eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_movies_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e309cb-878f-4ad7-be50-357f82410a5c",
   "metadata": {},
   "source": [
    "[TODO] - the counts seem off in both cases - find out more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a8258c-3540-46f2-bee5-f58b7a3f97ea",
   "metadata": {},
   "source": [
    "# Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2eefa9-c161-4f60-bedc-c7c59cba9181",
   "metadata": {},
   "source": [
    "1. Polars runs on Apache Arrow\n",
    "2. Columnar\n",
    "3. Strict data types\n",
    "4. Syntax varies from Pandas and Spark - exercise care\n",
    "5. Still growing (and fast!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd53572b-6b87-4a48-9d17-64d7b1a2404a",
   "metadata": {},
   "source": [
    "# Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7619586-3cce-4999-ad91-bbff02770cfd",
   "metadata": {},
   "source": [
    "* Let's play with the MovieLens dataset some more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
