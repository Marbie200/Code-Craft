{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "687af001-f355-4232-a4c5-d183f7c13460",
   "metadata": {},
   "source": [
    "# 10+ Minutes to pyArrow and Arrow DataFusion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d47412f-7828-4c9d-9d79-8d96a7f8facb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19d5c0db-f62b-408d-8ab5-9a744ba6a05a",
   "metadata": {},
   "source": [
    "This is WIP, just the basics are in place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667de2f7-bbf3-42bf-baee-3ece99d47797",
   "metadata": {},
   "source": [
    "# pyArrow Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6765161-ba33-4474-b3c5-418038b2ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19784171-dd18-4fe2-87fd-eefb44e9c835",
   "metadata": {},
   "source": [
    "## Arrays and Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b44856d-ff9f-4077-a55d-5bc633e6c99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = pa.array([1,12,17,23,28], type=pa.int8())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37b929a6-cccf-4778-850b-c57021a7c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = pa.array([1, 3, 5, 7, 1], type=pa.int8())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef9b8641-b1dd-49de-804a-474d3842f595",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = pa.array([1990, 2000, 1995, 2000, 1995], type=pa.int16())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53674302-c2e6-433c-99df-dc2ed635cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "birthdays_table = pa.table([days, months, years],\n",
    "                           names=[\"days\", \"months\", \"years\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "677010b6-238a-4547-85a1-b1cb9164a48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "days: int8\n",
       "months: int8\n",
       "years: int16\n",
       "----\n",
       "days: [[1,12,17,23,28]]\n",
       "months: [[1,3,5,7,1]]\n",
       "years: [[1990,2000,1995,2000,1995]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birthdays_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce883b7-7d61-4106-8472-cb2b05edf07f",
   "metadata": {},
   "source": [
    "## Saving and Loading Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf328825-b7a1-4549-a44d-de44f9963e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd807179-82c8-420b-a470-fad7c0f2c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.write_table(birthdays_table, './data/birthdays.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db97584-fd51-4f65-afa2-326df358d159",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_birthdays = pq.read_table('./data/birthdays.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24bb3b43-8de5-421c-ba3c-d1d7ee8f1d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "days: int8\n",
       "months: int8\n",
       "years: int16\n",
       "----\n",
       "days: [[1,12,17,23,28]]\n",
       "months: [[1,3,5,7,1]]\n",
       "years: [[1990,2000,1995,2000,1995]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_birthdays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f4fa6-42a9-4fe3-bcc5-3eb02f44e287",
   "metadata": {},
   "source": [
    "## Performing Computations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b85521-418b-4241-b887-72dcb2750bdf",
   "metadata": {},
   "source": [
    "Here's a [list of available compute functions](https://arrow.apache.org/docs/python/compute.html#compute) for our reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77eca07c-b6bb-4264-9409-15c3cb385bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.compute as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ff2ea42-1d1a-4168-a798-d49ff0b41996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.lib.StructArray object at 0x00000241AA9CA4A0>\n",
       "-- is_valid: all not null\n",
       "-- child 0 type: int16\n",
       "  [\n",
       "    1990,\n",
       "    2000,\n",
       "    1995\n",
       "  ]\n",
       "-- child 1 type: int64\n",
       "  [\n",
       "    1,\n",
       "    2,\n",
       "    2\n",
       "  ]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.value_counts(birthdays_table[\"years\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fa9b56-acc3-4b93-b2b6-29e0675e8977",
   "metadata": {},
   "source": [
    "## Working with large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4a00a7b-263b-41d0-9c2d-414b71e5361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.dataset as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4a7ffd-1c97-45c7-aa3b-d2b18f6e00f7",
   "metadata": {},
   "source": [
    "Arrow also provides the ```pyarrow.dataset``` API to work with large data, which will handle for you partitioning of your data in smaller chunks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cedb93d-8257-49e6-a8fd-4415ec3f4eef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Could not write to ./data/pyArrow-large-data/2 as the directory is not empty and existing_data_behavior is to error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbirthdays_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/pyArrow-large-data/2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartitioning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbirthdays_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfield\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myears\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\1\\a\\Lib\\site-packages\\pyarrow\\dataset.py:999\u001b[0m, in \u001b[0;36mwrite_dataset\u001b[1;34m(data, base_dir, basename_template, format, partitioning, partitioning_flavor, schema, filesystem, file_options, use_threads, max_partitions, max_open_files, max_rows_per_file, min_rows_per_group, max_rows_per_group, file_visitor, existing_data_behavior, create_dir)\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot specify a schema when writing a Scanner\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    997\u001b[0m     scanner \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m--> 999\u001b[0m \u001b[43m_filesystemdataset_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscanner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasename_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_partitions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_visitor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexisting_data_behavior\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_open_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows_per_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_rows_per_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows_per_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_dir\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\1\\a\\Lib\\site-packages\\pyarrow\\_dataset.pyx:3655\u001b[0m, in \u001b[0;36mpyarrow._dataset._filesystemdataset_write\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\1\\a\\Lib\\site-packages\\pyarrow\\error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowInvalid\u001b[0m: Could not write to ./data/pyArrow-large-data/2 as the directory is not empty and existing_data_behavior is to error"
     ]
    }
   ],
   "source": [
    "ds.write_dataset(birthdays_table, \"./data/pyArrow-large-data/2\", format=\"parquet\",\n",
    "                 partitioning=ds.partitioning(\n",
    "                    pa.schema([birthdays_table.schema.field(\"years\")])\n",
    "                ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de1745a-eb7f-4a1f-9c95-b51216838607",
   "metadata": {},
   "source": [
    "Loading back the partitioned dataset will detect the chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d0013-1bbd-4a13-9d24-607f5ea26c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "birthdays_dataset = ds.dataset(\"./data/pyArrow-large-data\", format=\"parquet\", partitioning=[\"years\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a66555-6a16-4ba5-9374-64a06b706000",
   "metadata": {},
   "outputs": [],
   "source": [
    "birthdays_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c9fceb-7a42-4a2b-831e-303c1d8e9f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "birthdays_dataset.files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38656b0e-c4ef-4a89-b9e8-d31b4eb07380",
   "metadata": {},
   "source": [
    "Arrow will lazily load chunks of data only when iterating over them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d799074-aa8c-4d98-947d-9053923f20e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "current_year = datetime.datetime.utcnow().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac08939-f0a1-4f11-9d78-943afd1a654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_chunk in birthdays_dataset.to_batches():\n",
    "    print(\"AGES\", pc.subtract(current_year, table_chunk[\"years\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb03430-8a43-477d-8224-92e1fdf941d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more to come, including DataFusion basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b1f97-5e97-4d8c-9044-43a84ac16c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
