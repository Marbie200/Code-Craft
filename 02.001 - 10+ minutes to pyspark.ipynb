{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a544b7b-bf71-4738-983a-56ed10e133eb",
   "metadata": {},
   "source": [
    "# Data Munging with PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bc95fc-c403-4556-8423-2ec83458f0db",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Installation etc.\n",
    "\n",
    "Look, I hate to be that guy, but Google/DDG are your friends here.  \n",
    "Getting ```Spark```, ```pySpark``` and other libraries to run is more than a little tedious.  \n",
    "The following are a 'best-guess' set of instrustions.  \n",
    "The ones that worked for me.  \n",
    "Using Windows 10 here.  \n",
    "Your mileage may vary.  \n",
    "\n",
    "Once you are through the tedium of installation and setup - it gets good. I promise. :)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ec543e-8ec3-4d72-9b03-9f4c62725514",
   "metadata": {},
   "source": [
    "## Download (and install where applicable)\n",
    "* JDK (prefer 8.x/11.x, 64bit, more open the better)\n",
    "* Hadoop (3.2.x, at this time) - _for windows, we just need Hadoop Winutils_\n",
    "* [Hadoop *winutils* (corresponding to the version of Hadoop)](https://github.com/cdarlint/winutils), [another repo](https://github.com/kontext-tech/winutils)\n",
    "* [Spark (3.x, at this time)](https://spark.apache.org/downloads.html)  \n",
    "* [Anaconda - Open Source/Individual Edition](https://www.anaconda.com/products/distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96b7fb1-d67d-4943-829f-7e21af47502f",
   "metadata": {},
   "source": [
    "## Setup environment variables \n",
    "\n",
    "We set these environment variables that help manage paths better.\n",
    "Example variable values would look like:\n",
    "Java:  \n",
    "* JAVA_HOME = ```C:\\[Java]```  \n",
    "    \n",
    "Hadoop:  \n",
    "* HADOOP_HOME = ```C:\\hadoop\\hadoop-3.2.1```  \n",
    "_On Windows 10, we just need HADOOP_HOME to be the folder where **winutils.exe** is located_\n",
    "\n",
    "finally, Spark:   \n",
    "* SPARK_HOME = ```C:\\Spark\\spark-3.2.1-bin-hadoop3.2```  \n",
    "\n",
    "*notice there are no backslashes in the end. This is because slashes will be added in the next step when we setup path*      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba7dbaa-30d1-41ba-8573-3470d74abd0e",
   "metadata": {},
   "source": [
    "## Update system **'PATH'**\n",
    "\n",
    "We use the variables defined above to set-up paths.  \n",
    "\n",
    "* Java: ```%JAVA_HOME%/bin```\n",
    "* Hadoop 01: ```%HADOOP_HOME%/bin```\n",
    "* Hadoop 02: ```%HADOOP_HOME%/sbin``` (*sbin needed in addition to bin*)\n",
    "* Spark: ```%SPARK_HOME%/bin```  \n",
    "    \n",
    "(*here we add backslashes before bin*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7301fb83-c2ee-42a9-9c2c-57226377c48f",
   "metadata": {},
   "source": [
    "## Patch Hadoop  \n",
    "\n",
    "This is *needed* when Hadoop is run on Windows.\n",
    "\n",
    "* copy the ```bin``` folder from the right version of winutils to replace ```%HADOOP_HOME%/bin```  \n",
    "\n",
    "* copy ```hadoop-yarn-server-timelineservice-3.0.3``` from ```%HADOOP_HOME%\\share\\hadoop\\yarn\\timelineservice``` to ```%HADOOP_HOME%\\share\\hadoop\\yarn``` (the parent directory).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca5cdca-66e7-4cb2-aacd-11d8379630c9",
   "metadata": {},
   "source": [
    "## Install the Python libraries\n",
    "\n",
    "Prefer installing [Anaconda](https://www.anaconda.com/products/distribution). \n",
    "It resolves other dependencies like Pandas, Numpy, Jupyter etc. too.  \n",
    "Once there, use either pip or conda - they are both cool but incompatible.  \n",
    "The conda-forge channel is a few days behind the pip one.  \n",
    "We're only running on the local machine here, no complicated infrastructure to care about.  \n",
    "So, you do you.  \n",
    "\n",
    "Use one of the following commands (from the command line obvs) to install each:  \n",
    "* pyspark:\n",
    "    * ```pip install pyspark``` or\n",
    "    * ```conda install -c conda-forge pyspark```\n",
    "* findspark:\n",
    "    * ```pip install findspark``` or\n",
    "    * ```conda install -c conda-forge findspark```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e98fc72-dbd6-49db-afc9-9c16e10385d3",
   "metadata": {},
   "source": [
    "## References  \n",
    "\n",
    "* [How to install Hadoop on Win 10](https://muhammadbilalyar.github.io/blogs/How-to-install-Hadoop-on-Window-10/)\n",
    "* [Hadoop on Windows](https://github.com/MuhammadBilalYar/Hadoop-On-Window)\n",
    "* [Hadoop and Spark on Windows](https://dev.to/awwsmm/installing-and-running-hadoop-and-spark-on-windows-33kc)\n",
    "\n",
    "### (_Optionally_) Configure Hadoop\n",
    "\n",
    "*only needed if you want to use hadoop as your file storage system*  \n",
    "\n",
    "* create a folder for ```namenode```\n",
    "* create a folder for ```datanode```\n",
    "* four files: ```core-site.xml```, ```mapred-site.xml```, ```hdfs-site.xml```, ```yarn-site.xml``` - see code for each in the [reference repo](https://github.com/MuhammadBilalYar/Hadoop-On-Window) above.\n",
    "\n",
    "### Also,\n",
    "\n",
    "The scope of this notebook is *usage* - not setup or troubleshooting, am pretty sure these installation instructions will be outdated soon and be replaced by pre-built docker images or shell scripts or automated installs for windows or such-like.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445cf8df-816d-4e9f-937d-f711263a2189",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "This boiler plate helps, esp. in Jupyter Notebook situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d7fca2-50cb-44d7-ae1e-e35ac201a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: initialize findspark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffcf28b-084b-4227-8bb3-d7a714c9e647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: import pyspark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa73c1c-b624-478a-ab4c-2b43dc896a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a spark session\n",
    "\n",
    "# 'local[1]' indicates spark on 1 core on the local machine, specify the number of cores needed\n",
    "# use .config(\"spark.some.config.option\", \"some-value\") for additional configuration\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('local[1]') \\\n",
    "    .appName(\"10+ minutes to pyspark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4196ac0a-608f-4632-a456-d30b1ed57efc",
   "metadata": {},
   "source": [
    "Back in the day you'd need various 'contexts' as entry points into spark functionality.  \n",
    "All of this is now wrapped into a SparkSession, easy to manage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4769ab4a-2aec-4324-9aec-c678e6f7929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SparkSession carries the sparkContext\n",
    "# spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b128f6-7001-4f98-8204-2e6ff76c4366",
   "metadata": {},
   "source": [
    "Check out the spark UI link when you uncomment the lines in the two cells above.  \n",
    "Your local UI should launch at a link like: http://localhost:4041/jobs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae8fd9ee-5023-46ed-8c2c-202ba45e138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we close the notebook, stop spark, otherwise Jupyter closes, but scala-spark keep going on...\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9596fcf-6641-4ccc-94fd-0cac6b4f28bf",
   "metadata": {},
   "source": [
    "# Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ce9eb-a318-4782-b83b-a3e1d1b03ad4",
   "metadata": {},
   "source": [
    "## DataFrames: Create and View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f8ace1-e5fe-473d-880f-dc41d2c2888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43a0c32e-9b00-42be-98b3-58759ab43864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a list of pyspark.sql.Row\n",
    "df1 = spark.createDataFrame(\n",
    "    [\n",
    "        Row(a=1,b=2.,c='span a',d=date(2022,7,1),e=datetime(2022,7,1,12,0)),\n",
    "        Row(a=1,b=3.,c='can a ',d=date(2022,7,2),e=datetime(2022,7,2,12,0,1)),\n",
    "        Row(a=1,b=4.,c='banana',d=date(2022,7,3),e=datetime(2022,7,3,12,0,2))\n",
    "    ]\n",
    ")\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3b8125b-16ca-49b9-9625-d2223b0faabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+----------+-------------------+\n",
      "|  a|  b|     c|         d|                  e|\n",
      "+---+---+------+----------+-------------------+\n",
      "|  1|2.0|span a|2022-07-01|2022-07-01 12:00:00|\n",
      "|  1|3.0|can a |2022-07-02|2022-07-02 12:00:01|\n",
      "|  1|4.0|banana|2022-07-03|2022-07-03 12:00:02|\n",
      "+---+---+------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df1's not been evaluated yet. It's lazy evaluation\n",
    "# to eval it, we go\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "019bdf5d-6461-41a7-a207-68ebf1e409e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a list of tuples with explicit schema\n",
    "df2 = spark.createDataFrame(\n",
    "    [\n",
    "        (2,5.,'man a',date(2022,7,1),datetime(2022,7,1,12,0)),\n",
    "        (2,6.,'can a',date(2022,8,1),datetime(2022,7,2,12,0)),\n",
    "        (2,7.,'manna',date(2022,9,1),datetime(2022,7,3,12,0))\n",
    "    ],\n",
    "    schema = 'a bigint, b double, c string, d date, e timestamp'\n",
    ")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2ba1bfe-4867-4ad1-8e33-acfa6b312b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use spark RDDs to create a dataframe\n",
    "# go to the sparksession's sparkContext to access parallelize method\n",
    "rdd3 = spark.sparkContext.parallelize(\n",
    "    [\n",
    "        (3,5., 'main', date(2022,7,1), datetime(2022,7,1,12,0,1)),\n",
    "        (3,5., 'brain', date(2022,7,1), datetime(2022,7,1,12,0,1)),\n",
    "        (3,5., 'pain', date(2022,7,1), datetime(2022,7,1,12,0,1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "df3 = spark.createDataFrame(rdd3, schema=['a','b','c','d','e'])\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66e30524-a08e-4f72-ad29-6a61b1fe3236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------+----------+-------------------+\n",
      "|  a|                 b|                c|         d|                  e|\n",
      "+---+------------------+-----------------+----------+-------------------+\n",
      "|  7|  2.06919879867935|gandalf's manager|2022-07-01|2022-07-01 12:00:01|\n",
      "|  1|1.2779543149855563|             said|2022-07-02|2022-07-02 12:00:02|\n",
      "|  4|-1.445713114804323|               no|2022-07-03|2022-07-03 12:00:03|\n",
      "+---+------------------+-----------------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# can also use a pandas dataframe to create a spark dataframe\n",
    "df4_pd = pd.DataFrame(\n",
    "    {\n",
    "        'a': np.random.randint(0,10, size = 3),\n",
    "        'b': np.random.randn(3),\n",
    "        'c': [\"gandalf's manager\", \"said\", 'no'],\n",
    "        'd': [date(2022,7,1),date(2022,7,2),date(2022,7,3)],\n",
    "        'e': [datetime(2022,7,1,12,0,1),datetime(2022,7,2,12,0,2),datetime(2022,7,3,12,0,3)]\n",
    "    }\n",
    ")\n",
    "\n",
    "df4 = spark.createDataFrame(df4_pd)\n",
    "\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29122a68-ee0c-4d07-b6d3-c6900a5cd713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2.069199</td>\n",
       "      <td>gandalf's manager</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-07-01 12:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.277954</td>\n",
       "      <td>said</td>\n",
       "      <td>2022-07-02</td>\n",
       "      <td>2022-07-02 12:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.445713</td>\n",
       "      <td>no</td>\n",
       "      <td>2022-07-03</td>\n",
       "      <td>2022-07-03 12:00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a         b                  c           d                   e\n",
       "0  7  2.069199  gandalf's manager  2022-07-01 2022-07-01 12:00:01\n",
       "1  1  1.277954               said  2022-07-02 2022-07-02 12:00:02\n",
       "2  4 -1.445713                 no  2022-07-03 2022-07-03 12:00:03"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d6bdf10-9527-4cad-8e71-1e2b4529c040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- a: long (nullable = true)\n",
      " |-- b: double (nullable = true)\n",
      " |-- c: string (nullable = true)\n",
      " |-- d: date (nullable = true)\n",
      " |-- e: timestamp (nullable = true)\n",
      "\n",
      "root\n",
      " |-- a: long (nullable = true)\n",
      " |-- b: double (nullable = true)\n",
      " |-- c: string (nullable = true)\n",
      " |-- d: date (nullable = true)\n",
      " |-- e: timestamp (nullable = true)\n",
      "\n",
      "root\n",
      " |-- a: long (nullable = true)\n",
      " |-- b: double (nullable = true)\n",
      " |-- c: string (nullable = true)\n",
      " |-- d: date (nullable = true)\n",
      " |-- e: timestamp (nullable = true)\n",
      "\n",
      "root\n",
      " |-- a: long (nullable = true)\n",
      " |-- b: double (nullable = true)\n",
      " |-- c: string (nullable = true)\n",
      " |-- d: date (nullable = true)\n",
      " |-- e: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use printSchema() to..., you know, it says what it does\n",
    "# also don't you hate that pySpark is following the Java camelCase instead of the Python snake_case?\n",
    "# yeah, what's that all about?\n",
    "\n",
    "df1.printSchema()\n",
    "df2.printSchema()\n",
    "df3.printSchema()\n",
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33356611-4248-4825-8cff-69377bba13cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+----------+-------------------+\n",
      "|  a|  b|     c|         d|                  e|\n",
      "+---+---+------+----------+-------------------+\n",
      "|  1|2.0|span a|2022-07-01|2022-07-01 12:00:00|\n",
      "+---+---+------+----------+-------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "-RECORD 0------------------\n",
      " a   | 7                   \n",
      " b   | 2.06919879867935    \n",
      " c   | gandalf's manager   \n",
      " d   | 2022-07-01          \n",
      " e   | 2022-07-01 12:00:01 \n",
      "-RECORD 1------------------\n",
      " a   | 1                   \n",
      " b   | 1.2779543149855563  \n",
      " c   | said                \n",
      " d   | 2022-07-02          \n",
      " e   | 2022-07-02 12:00:02 \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show only x rows\n",
    "df1.show(1)\n",
    "# vertical - if the row is too long for horizontal display\n",
    "df4.show(2, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecf225d7-710e-4e69-80f7-f63bd7a89147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(a=3, b=5.0, c='main', d=datetime.date(2022, 7, 1), e=datetime.datetime(2022, 7, 1, 12, 0, 1)),\n",
       " Row(a=3, b=5.0, c='brain', d=datetime.date(2022, 7, 1), e=datetime.datetime(2022, 7, 1, 12, 0, 1)),\n",
       " Row(a=3, b=5.0, c='pain', d=datetime.date(2022, 7, 1), e=datetime.datetime(2022, 7, 1, 12, 0, 1))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect() - collects the entire df from across all nodes to the driver\n",
    "# if you don't have enough memory, here's how you crash spark\n",
    "# careful is the word\n",
    "df3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d415b40-f85f-4a95-89de-189aa16e617f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(a=2, b=5.0, c='man a', d=datetime.date(2022, 7, 1), e=datetime.datetime(2022, 7, 1, 12, 0)),\n",
       " Row(a=2, b=6.0, c='can a', d=datetime.date(2022, 8, 1), e=datetime.datetime(2022, 7, 2, 12, 0))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas used to have a take() method, deprecated now\n",
    "# take() in spark extracts the first n rows of a dataframe\n",
    "df2.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f0d793a-a269-46c4-82ba-c3a9c5f4a89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(a=2, b=6.0, c='can a', d=datetime.date(2022, 8, 1), e=datetime.datetime(2022, 7, 2, 12, 0)),\n",
       " Row(a=2, b=7.0, c='manna', d=datetime.date(2022, 9, 1), e=datetime.datetime(2022, 7, 3, 12, 0))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as take() but returns the last n rows of a dataframe\n",
    "df2.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df8be5f3-ca9e-4103-8ec4-bc7a9acc3099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>main</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-07-01 12:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>brain</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-07-01 12:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>pain</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-07-01 12:00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a    b      c           d                   e\n",
       "0  3  5.0   main  2022-07-01 2022-07-01 12:00:01\n",
       "1  3  5.0  brain  2022-07-01 2022-07-01 12:00:01\n",
       "2  3  5.0   pain  2022-07-01 2022-07-01 12:00:01"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hey you want another way of crashing the spark driver?\n",
    "# convert the spark dataframe to a pandas dataframe\n",
    "# it'll collect all data from all workers into the driver\n",
    "df3.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f49288e-7455-4a84-b2bd-237ad913d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how do I make it so my dataframes are evaluated eagerly?\n",
    "# instead of the regular lazy eval?\n",
    "# y'know when am in notebooks and stuff?\n",
    "# set the config\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b60f9473-8440-417f-909b-dd7b6060fc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>a</th><th>b</th><th>c</th><th>d</th><th>e</th></tr>\n",
       "<tr><td>1</td><td>2.0</td><td>span a</td><td>2022-07-01</td><td>2022-07-01 12:00:00</td></tr>\n",
       "<tr><td>1</td><td>3.0</td><td>can a </td><td>2022-07-02</td><td>2022-07-02 12:00:01</td></tr>\n",
       "<tr><td>1</td><td>4.0</td><td>banana</td><td>2022-07-03</td><td>2022-07-03 12:00:02</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there you go, eager evaulatio'\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d446b176-8186-4aa7-bd72-e6e481b130fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set it back to false if you like\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2725b11-35f6-488a-95a1-eef0b27cec73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No more eagerly evaluated dataframes\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d15109-8688-4106-bb8f-e631b9b9f58a",
   "metadata": {},
   "source": [
    "# Selecting and Accessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37b63bf6-0858-44c2-b5f6-f76fec5dc681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Column<'a'>, Column<'b'>, Column<'c'>, Column<'d'>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access a column\n",
    "df1.a, df2.b, df3.c, df4.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d307d39a-b253-42fc-9891-1874efbff6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Column\n",
    "from pyspark.sql.functions import upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "893f2913-e512-40c1-b2db-592bbe923e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df1.c) == type(upper(df1.c)) == type(df1.c.isNull())\n",
    "# TODO: what's going on with type(df1.c.isNull()) above???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ea79385-3d12-4fd3-9b91-a69c0d068e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'(c IS NULL)'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.c.isNull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7aefb474-fc0d-4d9c-b702-84c4e9baa02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|     c|\n",
      "+------+\n",
      "|span a|\n",
      "|can a |\n",
      "|banana|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use dataframe's select method to identify a column and show() it\n",
    "df1.select(df1.c).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fe31305-cf4b-4956-8fe2-52381e13fa10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------+----------+-------------------+\n",
      "|  a|                 b|                c|         d|                  e|\n",
      "+---+------------------+-----------------+----------+-------------------+\n",
      "|  7|  2.06919879867935|gandalf's manager|2022-07-01|2022-07-01 12:00:01|\n",
      "|  1|1.2779543149855563|             said|2022-07-02|2022-07-02 12:00:02|\n",
      "|  4|-1.445713114804323|               no|2022-07-03|2022-07-03 12:00:03|\n",
      "+---+------------------+-----------------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# also there's dataframe.filter()\n",
    "df4.filter(df4.a>0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "989931c3-1191-4706-93e4-21f299b3ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7c17a5d-ae8a-4c45-998f-0685497d5202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------+----------+-------------------+-----------------+\n",
      "|  a|                 b|                c|         d|                  e|          upper_c|\n",
      "+---+------------------+-----------------+----------+-------------------+-----------------+\n",
      "|  7|  2.06919879867935|gandalf's manager|2022-07-01|2022-07-01 12:00:01|GANDALF'S MANAGER|\n",
      "|  1|1.2779543149855563|             said|2022-07-02|2022-07-02 12:00:02|             SAID|\n",
      "|  4|-1.445713114804323|               no|2022-07-03|2022-07-03 12:00:03|               NO|\n",
      "+---+------------------+-----------------+----------+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assign a new column instance to the dataframe\n",
    "df4_withNewCol = df4.withColumn('upper_c', upper(df4.c))\n",
    "df4_withNewCol.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "770ee356-4dad-47a9-9cfb-900231fec55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------+----------+-------------------+\n",
      "|  a|                 b|                c|         d|                  e|\n",
      "+---+------------------+-----------------+----------+-------------------+\n",
      "|  7|  2.06919879867935|gandalf's manager|2022-07-01|2022-07-01 12:00:01|\n",
      "|  1|1.2779543149855563|             said|2022-07-02|2022-07-02 12:00:02|\n",
      "|  4|-1.445713114804323|               no|2022-07-03|2022-07-03 12:00:03|\n",
      "+---+------------------+-----------------+----------+-------------------+\n",
      "\n",
      "+---+------------------+-----------------+----------+-------------------+-----------------+\n",
      "|  a|                 b|                c|         d|                  e|          upper_c|\n",
      "+---+------------------+-----------------+----------+-------------------+-----------------+\n",
      "|  7|  2.06919879867935|gandalf's manager|2022-07-01|2022-07-01 12:00:01|GANDALF'S MANAGER|\n",
      "|  1|1.2779543149855563|             said|2022-07-02|2022-07-02 12:00:02|             SAID|\n",
      "|  4|-1.445713114804323|               no|2022-07-03|2022-07-03 12:00:03|               NO|\n",
      "+---+------------------+-----------------+----------+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show()\n",
    "df4_withNewCol.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2b7c395-3668-46e5-89ae-ab801c5009ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+\n",
      "|  a|  b|  c|  d|  e|\n",
      "+---+---+---+---+---+\n",
      "+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "df4.filter(df4.a == 9).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37002785-5d6f-4d06-aa0e-dfa309dc24c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------+----------+-------------------+\n",
      "|  a|                 b|                c|         d|                  e|\n",
      "+---+------------------+-----------------+----------+-------------------+\n",
      "|  7|  2.06919879867935|gandalf's manager|2022-07-01|2022-07-01 12:00:01|\n",
      "|  1|1.2779543149855563|             said|2022-07-02|2022-07-02 12:00:02|\n",
      "+---+------------------+-----------------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.filter(df4.b > 0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b895559-ebb0-49df-849e-2bc5d5b1839d",
   "metadata": {},
   "source": [
    "# UDFs: Applying a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8705daf5-a919-4097-9280-a90630ec6871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|  a|pandas_plus_one(a)|\n",
      "+---+------------------+\n",
      "|  7|                 8|\n",
      "|  1|                 2|\n",
      "|  4|                 5|\n",
      "+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "\n",
    "@pandas_udf('long')\n",
    "def pandas_plus_one(series: pd.Series) -> pd.Series:\n",
    "    #     plus one using pandas series\n",
    "    return series+1\n",
    "\n",
    "df4.select(df4.a, pandas_plus_one(df4.a)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0d946c1-48cd-4693-a360-96bfb29ec43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------+----------+-------------------+\n",
      "|  a|                 b|                c|         d|                  e|\n",
      "+---+------------------+-----------------+----------+-------------------+\n",
      "|  7|  2.06919879867935|gandalf's manager|2022-07-01|2022-07-01 12:00:01|\n",
      "|  1|1.2779543149855563|             said|2022-07-02|2022-07-02 12:00:02|\n",
      "+---+------------------+-----------------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def pandas_filter(iterator):\n",
    "    for pandas_df in iterator:\n",
    "        yield pandas_df[pandas_df.b>0]\n",
    "        \n",
    "df4.mapInPandas(pandas_filter, schema = df4.schema).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d967daa8-65ea-4704-a097-32f22619c993",
   "metadata": {},
   "source": [
    "# Grouping Data\n",
    "\n",
    "Split-Apply-Combine, just like pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d2ba63a-e9db-477d-af55-bd6ffd955ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---+---+\n",
      "|color| fruit| v1| v2|\n",
      "+-----+------+---+---+\n",
      "|  red|banana|  1| 10|\n",
      "| blue|banana|  2| 20|\n",
      "|  red|carrot|  3| 30|\n",
      "| blue| grape|  4| 40|\n",
      "|  red|carrot|  5| 50|\n",
      "|black|carrot|  6| 60|\n",
      "|  red|banana|  7| 70|\n",
      "|  red| grape|  8| 80|\n",
      "+-----+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group by fruit, color etc.\n",
    "df5 = spark.createDataFrame([\n",
    "    ['red', 'banana', 1, 10], ['blue', 'banana', 2, 20], ['red', 'carrot', 3, 30],\n",
    "    ['blue', 'grape', 4, 40], ['red', 'carrot', 5, 50], ['black', 'carrot', 6, 60],\n",
    "    ['red', 'banana', 7, 70], ['red', 'grape', 8, 80]], schema=['color', 'fruit', 'v1', 'v2'])\n",
    "\n",
    "df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb849da3-352d-4ab6-aed7-bbd79307f4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+\n",
      "|color|avg(v1)|avg(v2)|\n",
      "+-----+-------+-------+\n",
      "|  red|    4.8|   48.0|\n",
      "|black|    6.0|   60.0|\n",
      "| blue|    3.0|   30.0|\n",
      "+-----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.groupby('color').avg().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a36dd4ae-b463-45ff-a328-63c53a67748c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---+---+\n",
      "|color| fruit| v1| v2|\n",
      "+-----+------+---+---+\n",
      "|black|carrot|  0| 60|\n",
      "| blue|banana| -1| 20|\n",
      "| blue| grape|  1| 40|\n",
      "|  red|banana| -3| 10|\n",
      "|  red|carrot| -1| 30|\n",
      "|  red|carrot|  0| 50|\n",
      "|  red|banana|  2| 70|\n",
      "|  red| grape|  3| 80|\n",
      "+-----+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: How to get the deviations in a new column?\n",
    "def plus_mean(pandas_df):\n",
    "    return pandas_df.assign(v1=pandas_df.v1 - pandas_df.v1.mean())\n",
    "\n",
    "df5.groupby('color').applyInPandas(plus_mean, schema = df5.schema).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "556e1244-6157-4f61-b7c9-fabb8a423db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-grouping and applying a function.\n",
    "\n",
    "df6 = spark.createDataFrame(\n",
    "    [\n",
    "        (20000101, 1, 1.0), \n",
    "        (20000101, 2, 2.0), \n",
    "        (20000102, 1, 3.0), \n",
    "        (20000102, 2, 4.0)\n",
    "    ],\n",
    "    ('time', 'id', 'v1')\n",
    ")\n",
    "\n",
    "df7 = spark.createDataFrame(\n",
    "    [\n",
    "        (20000101, 1, 'x'), \n",
    "        (20000101, 2, 'y')\n",
    "    ],\n",
    "    ('time', 'id', 'v2')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "424c472e-0e6e-45c0-83c4-be4a128fe8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asof_join(l, r):\n",
    "    return pd.merge_asof(l,r,on='time', by='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36b10405-0406-4526-be30-a4df2b2cd6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6_gb = df6.groupby('id')\n",
    "df7_gb = df7.groupby('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da0171df-3121-4a56-b78d-f20ef56fcae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_grp = df6_gb.cogroup(df7_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eae2ec3d-0699-4536-b048-a2f61be71fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+---+---+\n",
      "|    time| id| v1| v2|\n",
      "+--------+---+---+---+\n",
      "|20000101|  1|1.0|  x|\n",
      "|20000102|  1|3.0|  x|\n",
      "|20000101|  2|2.0|  y|\n",
      "|20000102|  2|4.0|  y|\n",
      "+--------+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rslt = co_grp.applyInPandas(asof_join, schema='time int, id int, v1 double, v2 string')\n",
    "rslt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9eb347-0c6b-4c7a-b95e-03f8e930e220",
   "metadata": {},
   "source": [
    "# Getting data in and out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "746de44d-7c20-456d-bee9-ad657f12b117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---+---+\n",
      "|color| fruit| v1| v2|\n",
      "+-----+------+---+---+\n",
      "|  red|banana|  1| 10|\n",
      "| blue|banana|  2| 20|\n",
      "|  red|carrot|  3| 30|\n",
      "| blue| grape|  4| 40|\n",
      "|  red|carrot|  5| 50|\n",
      "|black|carrot|  6| 60|\n",
      "|  red|banana|  7| 70|\n",
      "|  red| grape|  8| 80|\n",
      "+-----+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CSV\n",
    "# .mode('overwrite') can be taken out when needed.\n",
    "df5.write.mode('overwrite').csv('fruits.csv', header=True)\n",
    "spark.read.csv('fruits.csv', header=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2869caf-bb97-4d65-a439-abcd54b387b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---+---+\n",
      "|color| fruit| v1| v2|\n",
      "+-----+------+---+---+\n",
      "|  red|banana|  1| 10|\n",
      "| blue|banana|  2| 20|\n",
      "|  red|carrot|  3| 30|\n",
      "| blue| grape|  4| 40|\n",
      "|  red|carrot|  5| 50|\n",
      "|black|carrot|  6| 60|\n",
      "|  red|banana|  7| 70|\n",
      "|  red| grape|  8| 80|\n",
      "+-----+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parquet\n",
    "# .mode('overwrite') can be taken out when needed.\n",
    "df5.write.mode('overwrite').parquet('fruits.parquet')\n",
    "spark.read.parquet('fruits.parquet').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0bf0e5-675b-47de-aaff-30b8dda710ba",
   "metadata": {},
   "source": [
    "# Working with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2f76a79-4196-40a0-8911-2b16b90fb3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.createOrReplaceTempView('tableA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "71cf4ac5-9523-4837-bc7c-276ccd963317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       8|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select count(*) from tableA').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10234261-9c90-47cb-8f8f-bc6410cb67f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.add_one(s: pandas.core.series.Series) -> pandas.core.series.Series>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UDFs in SQL\n",
    "# register and invoke\n",
    "@pandas_udf('integer')\n",
    "def add_one(s: pd.Series) -> pd.Series:\n",
    "    return s+1\n",
    "\n",
    "spark.udf.register('add_one', add_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33d62221-e6d4-43dc-8864-455f64824782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n",
      "| v1|add_one(v1)|\n",
      "+---+-----------+\n",
      "|  1|          2|\n",
      "|  2|          3|\n",
      "|  3|          4|\n",
      "|  4|          5|\n",
      "|  5|          6|\n",
      "|  6|          7|\n",
      "|  7|          8|\n",
      "|  8|          9|\n",
      "+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT v1, add_one(v1) from tableA').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6c181f2-978c-44af-a436-08e6098b01ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|add_one(v1)|\n",
      "+-----------+\n",
      "|          2|\n",
      "|          3|\n",
      "|          4|\n",
      "|          5|\n",
      "|          6|\n",
      "|          7|\n",
      "|          8|\n",
      "|          9|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# can mix/match sql expressions \n",
    "# for e.g. take the expressions from above\n",
    "\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "df5.selectExpr('add_one(v1)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55466bb4-3b91-4d75-9848-937ec8020bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       8|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.select(expr('count(*)')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75739657-6e2e-4a58-b33d-43e0f3588cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|(count(1) > 0)|\n",
      "+--------------+\n",
      "|          true|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.select(expr('count(*)')>0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77513663-399f-400a-8be1-c66945461b82",
   "metadata": {},
   "source": [
    "# Pandas API on Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26873600-5e9e-4d32-813b-50a136f9256e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8097116d-aaea-404c-9911-0187a766bc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    2.0\n",
       "2    3.0\n",
       "3    NaN\n",
       "4    5.0\n",
       "5    NaN\n",
       "6    7.0\n",
       "7    8.0\n",
       "8    9.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pandas on spark series\n",
    "\n",
    "s1 = ps.Series([1,2,3,np.nan,5,np.nan,7,8,9])\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d4d032e-2d95-44ac-8df1-fe22957896af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>six</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a    b      c\n",
       "10  1  100    one\n",
       "20  2  200    two\n",
       "30  3  300  three\n",
       "40  4  400   four\n",
       "50  5  500   five\n",
       "60  6  600    six"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf1 = ps.DataFrame(\n",
    "    {'a': [1, 2, 3, 4, 5, 6],\n",
    "     'b': [100, 200, 300, 400, 500, 600],\n",
    "     'c': [\"one\", \"two\", \"three\", \"four\", \"five\", \"six\"]\n",
    "    },\n",
    "    index=[10, 20, 30, 40, 50, 60]\n",
    ")\n",
    "\n",
    "psdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8fdb212-22f8-41f3-b328-71784cb501f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas dataframe and convert to pandas-spark\n",
    "dates1 = pd.date_range('20220101', periods=6)\n",
    "pdf1 = pd.DataFrame(np.random.randn(6,4), index=dates1, columns = list('ABCD'))\n",
    "# create spark dataframe from the pandas dataframe\n",
    "psdf1 = ps.from_pandas(pdf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f5c202f-86a7-497c-b3ea-6d7101cef227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>-0.180368</td>\n",
       "      <td>-0.071954</td>\n",
       "      <td>-0.969922</td>\n",
       "      <td>1.754936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02</th>\n",
       "      <td>2.809529</td>\n",
       "      <td>-0.330146</td>\n",
       "      <td>0.274938</td>\n",
       "      <td>-0.511405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>-0.993214</td>\n",
       "      <td>-1.811281</td>\n",
       "      <td>0.425113</td>\n",
       "      <td>-0.436873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>0.088916</td>\n",
       "      <td>0.336168</td>\n",
       "      <td>0.368839</td>\n",
       "      <td>0.010667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>0.347266</td>\n",
       "      <td>0.703723</td>\n",
       "      <td>0.758730</td>\n",
       "      <td>-0.819830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>-0.823590</td>\n",
       "      <td>-0.639242</td>\n",
       "      <td>-1.192412</td>\n",
       "      <td>0.186218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2022-01-01 -0.180368 -0.071954 -0.969922  1.754936\n",
       "2022-01-02  2.809529 -0.330146  0.274938 -0.511405\n",
       "2022-01-03 -0.993214 -1.811281  0.425113 -0.436873\n",
       "2022-01-04  0.088916  0.336168  0.368839  0.010667\n",
       "2022-01-05  0.347266  0.703723  0.758730 -0.819830\n",
       "2022-01-06 -0.823590 -0.639242 -1.192412  0.186218"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "608b5c19-d254-47b1-8db9-3469a0d7c5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-------------------+--------------------+\n",
      "|                  A|                   B|                  C|                   D|\n",
      "+-------------------+--------------------+-------------------+--------------------+\n",
      "|-0.1803676446120318|-0.07195374148708228|-0.9699224383554612|   1.754936270711452|\n",
      "| 2.8095287412059653|-0.33014550044668356|0.27493761020477425| -0.5114051599724003|\n",
      "|-0.9932135592367661| -1.8112805783021024|0.42511273144125733|-0.43687264087575084|\n",
      "|0.08891577560108033| 0.33616818654299235| 0.3688387884737041|  0.0106672238161948|\n",
      "|0.34726638819126543|  0.7037233061126154| 0.7587298906825163|  -0.819830479668479|\n",
      "|-0.8235902111006436| -0.6392421962423047|-1.1924118488403428| 0.18621838183614017|\n",
      "+-------------------+--------------------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a SPARK df from a PANDAS df (we've done this before)\n",
    "# create a PANDAS-ON-SPARK df from a SPARK df (we've done this too...)\n",
    "\n",
    "sdf2 = spark.createDataFrame(pdf1)\n",
    "sdf2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4124fe81-2591-4177-bfb1-4ccdbd0dd217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.180368</td>\n",
       "      <td>-0.071954</td>\n",
       "      <td>-0.969922</td>\n",
       "      <td>1.754936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.809529</td>\n",
       "      <td>-0.330146</td>\n",
       "      <td>0.274938</td>\n",
       "      <td>-0.511405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.993214</td>\n",
       "      <td>-1.811281</td>\n",
       "      <td>0.425113</td>\n",
       "      <td>-0.436873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.088916</td>\n",
       "      <td>0.336168</td>\n",
       "      <td>0.368839</td>\n",
       "      <td>0.010667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.347266</td>\n",
       "      <td>0.703723</td>\n",
       "      <td>0.758730</td>\n",
       "      <td>-0.819830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.823590</td>\n",
       "      <td>-0.639242</td>\n",
       "      <td>-1.192412</td>\n",
       "      <td>0.186218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "0 -0.180368 -0.071954 -0.969922  1.754936\n",
       "1  2.809529 -0.330146  0.274938 -0.511405\n",
       "2 -0.993214 -1.811281  0.425113 -0.436873\n",
       "3  0.088916  0.336168  0.368839  0.010667\n",
       "4  0.347266  0.703723  0.758730 -0.819830\n",
       "5 -0.823590 -0.639242 -1.192412  0.186218"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf2 = sdf2.pandas_api()\n",
    "# this works like a pandas df now...\n",
    "psdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b9b4b6c-103c-4c90-95c1-5ff34214bcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    float64\n",
       "B    float64\n",
       "C    float64\n",
       "D    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f1303255-1f39-42e8-8d76-c9ba054dff9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.180368</td>\n",
       "      <td>-0.071954</td>\n",
       "      <td>-0.969922</td>\n",
       "      <td>1.754936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.809529</td>\n",
       "      <td>-0.330146</td>\n",
       "      <td>0.274938</td>\n",
       "      <td>-0.511405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.993214</td>\n",
       "      <td>-1.811281</td>\n",
       "      <td>0.425113</td>\n",
       "      <td>-0.436873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.088916</td>\n",
       "      <td>0.336168</td>\n",
       "      <td>0.368839</td>\n",
       "      <td>0.010667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.347266</td>\n",
       "      <td>0.703723</td>\n",
       "      <td>0.758730</td>\n",
       "      <td>-0.819830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "0 -0.180368 -0.071954 -0.969922  1.754936\n",
       "1  2.809529 -0.330146  0.274938 -0.511405\n",
       "2 -0.993214 -1.811281  0.425113 -0.436873\n",
       "3  0.088916  0.336168  0.368839  0.010667\n",
       "4  0.347266  0.703723  0.758730 -0.819830"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas head()\n",
    "psdf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e3f80c80-1f13-450c-8c5d-0f7f3ac3d181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 2, 3, 4, 5], dtype='int64')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "836234ff-538c-44e1-ac85-ec0eb74c26dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A', 'B', 'C', 'D'], dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "be81bd98-1c33-4916-9457-f269ec38f28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.208090</td>\n",
       "      <td>-0.302122</td>\n",
       "      <td>-0.055786</td>\n",
       "      <td>0.030619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.375460</td>\n",
       "      <td>0.879103</td>\n",
       "      <td>0.813873</td>\n",
       "      <td>0.920161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.993214</td>\n",
       "      <td>-1.811281</td>\n",
       "      <td>-1.192412</td>\n",
       "      <td>-0.819830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.823590</td>\n",
       "      <td>-0.639242</td>\n",
       "      <td>-0.969922</td>\n",
       "      <td>-0.511405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.180368</td>\n",
       "      <td>-0.330146</td>\n",
       "      <td>0.274938</td>\n",
       "      <td>-0.436873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.347266</td>\n",
       "      <td>0.336168</td>\n",
       "      <td>0.425113</td>\n",
       "      <td>0.186218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.809529</td>\n",
       "      <td>0.703723</td>\n",
       "      <td>0.758730</td>\n",
       "      <td>1.754936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A         B         C         D\n",
       "count  6.000000  6.000000  6.000000  6.000000\n",
       "mean   0.208090 -0.302122 -0.055786  0.030619\n",
       "std    1.375460  0.879103  0.813873  0.920161\n",
       "min   -0.993214 -1.811281 -1.192412 -0.819830\n",
       "25%   -0.823590 -0.639242 -0.969922 -0.511405\n",
       "50%   -0.180368 -0.330146  0.274938 -0.436873\n",
       "75%    0.347266  0.336168  0.425113  0.186218\n",
       "max    2.809529  0.703723  0.758730  1.754936"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d8614d3b-cbb0-4c62-9a6f-6aa0f7bc639e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\1\\spark\\spark-3.3.0-bin-hadoop3\\python\\pyspark\\pandas\\utils.py:975: PandasAPIOnSparkAdviceWarning: `to_numpy` loads all data into the driver's memory. It should only be used if the resulting NumPy ndarray is expected to be small.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.18036764, -0.07195374, -0.96992244,  1.75493627],\n",
       "       [ 2.80952874, -0.3301455 ,  0.27493761, -0.51140516],\n",
       "       [-0.99321356, -1.81128058,  0.42511273, -0.43687264],\n",
       "       [ 0.08891578,  0.33616819,  0.36883879,  0.01066722],\n",
       "       [ 0.34726639,  0.70372331,  0.75872989, -0.81983048],\n",
       "       [-0.82359021, -0.6392422 , -1.19241185,  0.18621838]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# warning - this breaks the driver due to memory - just like collect()\n",
    "# be careful\n",
    "psdf2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f2a2d82e-ed61-47b9-9bc3-26bfc5d669ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>-0.180368</td>\n",
       "      <td>2.809529</td>\n",
       "      <td>-0.993214</td>\n",
       "      <td>0.088916</td>\n",
       "      <td>0.347266</td>\n",
       "      <td>-0.823590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-0.071954</td>\n",
       "      <td>-0.330146</td>\n",
       "      <td>-1.811281</td>\n",
       "      <td>0.336168</td>\n",
       "      <td>0.703723</td>\n",
       "      <td>-0.639242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>-0.969922</td>\n",
       "      <td>0.274938</td>\n",
       "      <td>0.425113</td>\n",
       "      <td>0.368839</td>\n",
       "      <td>0.758730</td>\n",
       "      <td>-1.192412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>1.754936</td>\n",
       "      <td>-0.511405</td>\n",
       "      <td>-0.436873</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>-0.819830</td>\n",
       "      <td>0.186218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5\n",
       "A -0.180368  2.809529 -0.993214  0.088916  0.347266 -0.823590\n",
       "B -0.071954 -0.330146 -1.811281  0.336168  0.703723 -0.639242\n",
       "C -0.969922  0.274938  0.425113  0.368839  0.758730 -1.192412\n",
       "D  1.754936 -0.511405 -0.436873  0.010667 -0.819830  0.186218"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose\n",
    "psdf2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ff44ab7-bbe1-47d6-851c-785c410ec46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.823590</td>\n",
       "      <td>-0.639242</td>\n",
       "      <td>-1.192412</td>\n",
       "      <td>0.186218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.347266</td>\n",
       "      <td>0.703723</td>\n",
       "      <td>0.758730</td>\n",
       "      <td>-0.819830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.088916</td>\n",
       "      <td>0.336168</td>\n",
       "      <td>0.368839</td>\n",
       "      <td>0.010667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.993214</td>\n",
       "      <td>-1.811281</td>\n",
       "      <td>0.425113</td>\n",
       "      <td>-0.436873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.809529</td>\n",
       "      <td>-0.330146</td>\n",
       "      <td>0.274938</td>\n",
       "      <td>-0.511405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.180368</td>\n",
       "      <td>-0.071954</td>\n",
       "      <td>-0.969922</td>\n",
       "      <td>1.754936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "5 -0.823590 -0.639242 -1.192412  0.186218\n",
       "4  0.347266  0.703723  0.758730 -0.819830\n",
       "3  0.088916  0.336168  0.368839  0.010667\n",
       "2 -0.993214 -1.811281  0.425113 -0.436873\n",
       "1  2.809529 -0.330146  0.274938 -0.511405\n",
       "0 -0.180368 -0.071954 -0.969922  1.754936"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort index\n",
    "psdf2.sort_index(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "24421bcc-fc85-45e7-a815-8240ffe9549f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.993214</td>\n",
       "      <td>-1.811281</td>\n",
       "      <td>0.425113</td>\n",
       "      <td>-0.436873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.823590</td>\n",
       "      <td>-0.639242</td>\n",
       "      <td>-1.192412</td>\n",
       "      <td>0.186218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.809529</td>\n",
       "      <td>-0.330146</td>\n",
       "      <td>0.274938</td>\n",
       "      <td>-0.511405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.180368</td>\n",
       "      <td>-0.071954</td>\n",
       "      <td>-0.969922</td>\n",
       "      <td>1.754936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.088916</td>\n",
       "      <td>0.336168</td>\n",
       "      <td>0.368839</td>\n",
       "      <td>0.010667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.347266</td>\n",
       "      <td>0.703723</td>\n",
       "      <td>0.758730</td>\n",
       "      <td>-0.819830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "2 -0.993214 -1.811281  0.425113 -0.436873\n",
       "5 -0.823590 -0.639242 -1.192412  0.186218\n",
       "1  2.809529 -0.330146  0.274938 -0.511405\n",
       "0 -0.180368 -0.071954 -0.969922  1.754936\n",
       "3  0.088916  0.336168  0.368839  0.010667\n",
       "4  0.347266  0.703723  0.758730 -0.819830"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort values\n",
    "psdf2.sort_values(by='B', ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c44fe2-a0f9-4689-b6d3-cb8de4fff888",
   "metadata": {},
   "source": [
    "# Missing Data - Pandas on Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec03db1-6e6f-4be8-9edf-0070d6003588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e3352-2c85-4ae1-8d56-6feb75edcd84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b228f0-e92b-4850-a179-ac448fb8cffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
