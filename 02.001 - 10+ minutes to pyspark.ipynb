{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a544b7b-bf71-4738-983a-56ed10e133eb",
   "metadata": {},
   "source": [
    "# Data Munging with PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bc95fc-c403-4556-8423-2ec83458f0db",
   "metadata": {},
   "source": [
    "# Installation etc.\n",
    "\n",
    "Setting up Spark and it's dependencies is a little tedious. \n",
    "Using Windows here. \n",
    "\n",
    "1. Download \n",
    "\t- JDK (prefer 8.x, 64bit)\n",
    "\t- Hadoop (3.2.x, at this time) - for windows, we just need Hadoop Winutils\n",
    "\t- [Hadoop winutils (corresponding to the version of Hadoop)](https://github.com/cdarlint/winutils), [another repo](https://github.com/kontext-tech/winutils)\n",
    "\t- [Spark (3.x, at this time)](https://spark.apache.org/downloads.html)  \n",
    "    \n",
    "    \n",
    "1. Setup environment variables (*notice there are no backslashes in the end. This is because slashes will be added in the next step when we setup path*), example paths would look like:\n",
    "\t- JAVA_HOME = ```C:\\[Java]``` \n",
    "\t- HADOOP_HOME = ```C:\\Hadoop\\hadoop-3.2.1```\n",
    "\t- SPARK_HOME = ```C:\\Spark\\spark-3.2.1-bin-hadoop3.2```  \n",
    "    \n",
    "    \n",
    "1. Update system 'path' (*here we add backslashes before bin*) to add the following:\n",
    "\t- Java: ```%JAVA_HOME%/bin```\n",
    "\t- Hadoop 01: ```%HADOOP_HOME%/bin```\n",
    "\t- Hadoop 02: ```%HADOOP_HOME%/sbin``` (*sbin needed in addition to bin*)\n",
    "\t- Spark: ```%SPARK_HOME%/bin```  \n",
    "    \n",
    "    \n",
    "1. Configure Hadoop (*optional, only needed if you want to use hadoop as your file storage system*):\n",
    "\t- create a folder for ```namenode```\n",
    "\t- create a folder for ```datanode```\n",
    "\t- four files: ```core-site.xml```, ```mapred-site.xml```, ```hdfs-site.xml```, ```yarn-site.xml``` - see code for each in the repo.  \n",
    "    \n",
    "    \n",
    "1. Patch Hadoop (this is only needed when Hadoop is run on Windows):\n",
    "\t- copy the ```bin``` folder from the right version of winutils to replace ```%HADOOP_HOME%/bin``` \n",
    "\t- copy ```hadoop-yarn-server-timelineservice-3.0.3``` from ```%HADOOP_HOME%\\share\\hadoop\\yarn\\timelineservice``` to ```%HADOOP_HOME%\\share\\hadoop\\yarn``` (the parent directory).  \n",
    "    \n",
    "    \n",
    "1. References:\n",
    "\t- ```https://muhammadbilalyar.github.io/blogs/How-to-install-Hadoop-on-Window-10/```\n",
    "\t- ```https://github.com/MuhammadBilalYar/Hadoop-On-Window```\n",
    "\t- ```https://dev.to/awwsmm/installing-and-running-hadoop-and-spark-on-windows-33kc```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445cf8df-816d-4e9f-937d-f711263a2189",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "This boiler plate helps, esp. in Jupyter Notebook situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d7fca2-50cb-44d7-ae1e-e35ac201a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: initialize findspark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffcf28b-084b-4227-8bb3-d7a714c9e647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: import pyspark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faa73c1c-b624-478a-ab4c-2b43dc896a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LCS64.mshome.net:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>10+ minutes to pyspark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1ec2a8a59d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Create a spark session\n",
    "\n",
    "# 'local[1]' indicates spark on 1 core on the local machine, specify the number of cores needed\n",
    "# use .config(\"spark.some.config.option\", \"some-value\") for additional configuration\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('local[1]') \\\n",
    "    .appName(\"10+ minutes to pyspark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4196ac0a-608f-4632-a456-d30b1ed57efc",
   "metadata": {},
   "source": [
    "Back in the day you'd need various 'contexts' as entry points into spark functionality.  \n",
    "All of this is now wrapped into a SparkSession, easy to manage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4769ab4a-2aec-4324-9aec-c678e6f7929e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LCS64.mshome.net:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>10+ minutes to pyspark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[1] appName=10+ minutes to pyspark>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The SparkSession carries the sparkContext\n",
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b128f6-7001-4f98-8204-2e6ff76c4366",
   "metadata": {},
   "source": [
    "Check out the spark UI link above.  \n",
    "Your local UI should launch at a link like: http://localhost:4041/jobs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8fd9ee-5023-46ed-8c2c-202ba45e138c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671445dc-e018-438a-a6ce-e15ecffc337b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91fd226-eddf-45e0-9d8f-3b9fca5fee69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f8ace1-e5fe-473d-880f-dc41d2c2888f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19561ad4-bb63-4817-baf6-0422fef587fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
