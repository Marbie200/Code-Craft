Data munging using:
* 00 [Numpy]()
* 01 [Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html)
* 02 [Spark](https://spark.apache.org/docs/latest/api/python/user_guide/index.html)
* 03 [Dask](https://docs.dask.org/en/stable/10-minutes-to-dask.html)
* 04 [Ray](https://www.ray.io/)

_possibly [vaex](https://vaex.io/docs/tutorials.html) 
and [optimus](https://docs.hi-optimus.com/en/latest/) in future_

# 00 Numpy

* [Numpy User Guide (v1.23 as of this)](https://numpy.org/doc/stable/user/index.html#user)
* [Numpy Tutorials](https://numpy.org/numpy-tutorials/features.html)


# 01 Pandas
 
* [Pandas 1.4.3 User Guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html)
* [10 minutes to pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)


# 02 Spark

We are using PySpark first. 
Future State: if time permits will try a bunch of Scala Notebooks too.
* 
* 


# 03 Dask

The approach is different: Dask focusses on Task scheduling vs Spark's Map-Reduce 

* [10 minutes to Dask](https://docs.dask.org/en/stable/10-minutes-to-dask.html)
* [90-minute Dask tutorial video](https://www.youtube.com/watch?v=_u0OQm9qf_A)
* [Talks and tutorials page](https://docs.dask.org/en/latest/presentations.html)


# 04 Ray

* [Ray Core](https://docs.ray.io/en/latest/ray-core/user-guide.html)
* [Ray Dataset Quickstart] (https://docs.ray.io/en/latest/data/getting-started.html#datasets-getting-started)
* [Ray Data] (https://docs.ray.io/en/latest/data/user-guide.html)