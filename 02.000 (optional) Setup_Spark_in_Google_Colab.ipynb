{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runnning Spark in Google Colab  \n",
    "\n",
    "The notebook here will explain how to download and install Apache Spark in a Google Colab environment.\n",
    "You can directly open this notebook in Colab using the following button:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/shauryashaurya/learn-data-munging/blob/main/02.000%20(optional)%20Setup_Spark_in_Google_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQ2J1c0zRg7D",
    "outputId": "46f7c939-4a29-45e2-da07-1cc353346e08"
   },
   "outputs": [],
   "source": [
    "# find out OS details\n",
    "! cat /etc/os-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Pt_uDtJRko8",
    "outputId": "1afaa5ae-fa82-4e9a-bc28-fb25a12a1989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"11.0.17\" 2022-10-18\n",
      "OpenJDK Runtime Environment (build 11.0.17+8-post-Ubuntu-1ubuntu218.04)\n",
      "OpenJDK 64-Bit Server VM (build 11.0.17+8-post-Ubuntu-1ubuntu218.04, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "# see if java is available\n",
    "! java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jycPMjnJWUlG",
    "outputId": "a4c44a9e-4348-437e-bf5a-de96c1701d56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java: /usr/bin/java /usr/share/java /usr/share/man/man1/java.1.gz\n"
     ]
    }
   ],
   "source": [
    "# spark needs JAVA_HOME and SPARK_HOME variables set.\n",
    "# to do that\n",
    "# we've got to locate java\n",
    "! whereis java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2BkgXWcdWxje",
    "outputId": "602450d0-23f5-4495-e73c-5c13a513b261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/lib/dpkg/info/openjdk-11-jdk-headless:amd64.prerm\n",
      "/var/lib/dpkg/info/openjdk-11-jre-headless:amd64.conffiles\n",
      "/var/lib/dpkg/info/openjdk-11-jdk-headless:amd64.md5sums\n",
      "/var/lib/dpkg/info/openjdk-11-jre-headless:amd64.list\n",
      "/var/lib/dpkg/info/openjdk-11-jre-headless:amd64.postinst\n",
      "/var/lib/dpkg/info/openjdk-11-jdk-headless:amd64.list\n",
      "/var/lib/dpkg/info/openjdk-11-jre:amd64.prerm\n",
      "/var/lib/dpkg/info/openjdk-11-jre:amd64.md5sums\n",
      "/var/lib/dpkg/info/openjdk-11-jre:amd64.postinst\n",
      "/var/lib/dpkg/info/openjdk-11-jre:amd64.list\n",
      "/var/lib/dpkg/info/openjdk-11-jdk-headless:amd64.postinst\n",
      "/var/lib/dpkg/info/openjdk-11-jre-headless:amd64.prerm\n",
      "/var/lib/dpkg/info/openjdk-11-jdk-headless:amd64.preinst\n",
      "/var/lib/dpkg/info/openjdk-11-jre-headless:amd64.md5sums\n",
      "/var/lib/dpkg/info/openjdk-11-jre-headless:amd64.postrm\n",
      "/usr/lib/jvm/java-11-openjdk-amd64\n",
      "/usr/lib/jvm/.java-1.11.0-openjdk-amd64.jinfo\n",
      "/usr/lib/jvm/java-1.11.0-openjdk-amd64\n",
      "/usr/lib/debug/usr/lib/jvm/java-11-openjdk-amd64\n",
      "/usr/lib/debug/usr/lib/jvm/java-1.11.0-openjdk-amd64\n",
      "/usr/share/pixmaps/openjdk-11.xpm\n",
      "/usr/share/lintian/overrides/openjdk-11-jre\n",
      "/usr/share/lintian/overrides/openjdk-11-jre-headless\n",
      "/usr/share/doc/openjdk-11-jre\n",
      "/usr/share/doc/openjdk-11-jdk-headless\n",
      "/usr/share/doc/openjdk-11-jre-headless\n",
      "/usr/share/gdb/auto-load/usr/lib/jvm/java-11-openjdk-amd64\n",
      "/usr/share/apport/package-hooks/source_openjdk-lts.py\n",
      "/usr/share/mime-info/openjdk-11-archive.mime\n",
      "/usr/share/mime-info/openjdk-11-archive.keys\n",
      "/usr/share/applications/openjdk-11-java.desktop\n",
      "/usr/share/application-registry/openjdk-11-archive.applications\n",
      "/usr/share/icons/hicolor/16x16/apps/openjdk-11.png\n",
      "/usr/share/icons/hicolor/24x24/apps/openjdk-11.png\n",
      "/usr/share/icons/hicolor/48x48/apps/openjdk-11.png\n",
      "/usr/share/icons/hicolor/32x32/apps/openjdk-11.png\n",
      "find: ‘/proc/45/task/45/net’: Invalid argument\n",
      "find: ‘/proc/45/net’: Invalid argument\n"
     ]
    }
   ],
   "source": [
    "# let's check more details so we can supply exact details to JAVA_HOME\n",
    "! find / -iname \"*openjdk-*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Akd__KdqSWRF"
   },
   "outputs": [],
   "source": [
    "# grab spark\n",
    "# as of Dec 2022, the latest version is 3.2.3, get the link from Apache Spark's website\n",
    "! wget -q https://dlcdn.apache.org/spark/spark-3.2.3/spark-3.2.3-bin-hadoop3.2.tgz\n",
    "# unzip spark\n",
    "!tar xf spark-3.2.3-bin-hadoop3.2.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53U4TuMITsAi"
   },
   "outputs": [],
   "source": [
    "# install findspark package\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jlhN6wvBVfrY",
    "outputId": "531952de-1908-40f2-9c9f-b081a30ec699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data  spark-3.2.3-bin-hadoop3.2\tspark-3.2.3-bin-hadoop3.2.tgz\n"
     ]
    }
   ],
   "source": [
    "# now the folder we are working in is \"content\"\n",
    "! ls ../content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6B0UuvPVtBM"
   },
   "outputs": [],
   "source": [
    "# got to provide JAVA_HOME and SPARK_HOME vairables\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.3-bin-hadoop3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xITc7EjHdHEu"
   },
   "outputs": [],
   "source": [
    "# Now we initialize spark like before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jEVYi6mUYZ-"
   },
   "outputs": [],
   "source": [
    "# Step 1: initialize findspark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "dbblGcx7csTM",
    "outputId": "8adce291-057c-469b-a678-9fd814cda511"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'3.2.3'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: import pyspark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWqPQh1DcwTb"
   },
   "outputs": [],
   "source": [
    "# Step 3: Create a spark session\n",
    "\n",
    "# 'local[1]' indicates spark on 1 core on the local machine (the Ubuntu VM on colab in this case), \n",
    "# specify the number of cores needed - we'll use local[*] in this case to engage as many cores as available\n",
    "# use .config(\"spark.some.config.option\", \"some-value\") for additional configuration\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"Setup-Spark-in-Google-Colab\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "XjSJWTY8c4xj",
    "outputId": "a8f84a28-9b3e-45ea-e00e-82b5302327cc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://951befdfdece:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>10+ minutes to pyspark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa7984db190>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PARHZ5SzdcNA"
   },
   "outputs": [],
   "source": [
    "# Let's download and unzip the MovieLens 25M Dataset as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-rrkiGzrlAzH"
   },
   "outputs": [],
   "source": [
    "! wget -q https://files.grouplens.org/datasets/movielens/ml-25m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1BqQDILlEZV",
    "outputId": "d5cb6a45-8c90-49de-82c7-254523da6b60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  ml-25m.zip  ml-25m.zip.1\tsample_data\n"
     ]
    }
   ],
   "source": [
    "! mkdir ./data\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QLGyv3m0lKAN",
    "outputId": "434209f3-3688-4716-eea9-d92af3a3858a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./ml-25m.zip\n",
      "   creating: ./data/ml-25m/\n",
      "  inflating: ./data/ml-25m/tags.csv  \n",
      "  inflating: ./data/ml-25m/links.csv  \n",
      "  inflating: ./data/ml-25m/README.txt  \n",
      "  inflating: ./data/ml-25m/ratings.csv  \n",
      "  inflating: ./data/ml-25m/genome-tags.csv  \n",
      "  inflating: ./data/ml-25m/genome-scores.csv  \n",
      "  inflating: ./data/ml-25m/movies.csv  \n"
     ]
    }
   ],
   "source": [
    "! unzip ./ml-25m.zip -d ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ho_rxhVMlLtD",
    "outputId": "58798053-ed2c-46ff-b6ea-9df54cf007a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genome-scores.csv  links.csv   ratings.csv  tags.csv\n",
      "genome-tags.csv    movies.csv  README.txt\n"
     ]
    }
   ],
   "source": [
    "! ls ./data/ml-25m/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNp7aqZtczcFGhiJ6YOlcwF",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
